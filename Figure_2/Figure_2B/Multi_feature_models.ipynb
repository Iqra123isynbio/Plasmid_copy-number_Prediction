{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc74e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# FILE PATH \n",
    "input_file = \"Multi_features_Models_training_data.csv\"  \n",
    "df = pd.read_csv(input_file)\n",
    "print(\"✅ File loaded successfully!\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# FEATURE SLICING \n",
    "start_idx   = 2\n",
    "kmer_count  = 84\n",
    "end_idx     = start_idx + kmer_count  \n",
    "X_kmers = df.iloc[:, start_idx:end_idx]\n",
    "\n",
    "domain_start  = end_idx\n",
    "domain_count  = 1288\n",
    "domain_end    = domain_start + domain_count  \n",
    "X_domains = df.iloc[:, domain_start:domain_end]\n",
    "\n",
    "length_cols = ['Total_Chromosome_Length', 'Plasmid_Length']\n",
    "X_lengths = df[length_cols]\n",
    "\n",
    "y = df['Log1p_PIRACopyNumber']\n",
    "\n",
    "print(f\"\\nShapes check:\")\n",
    "print(f\"  K-mers:   {X_kmers.shape}\")\n",
    "print(f\"  Domains:  {X_domains.shape}\")\n",
    "print(f\"  Lengths:  {X_lengths.shape}\")\n",
    "print(f\"  Target:   {y.shape}\")\n",
    "\n",
    "# PREPARE OUTPUT DIRECTORIES\n",
    "out_dir = \"Final_files\"  # GitHub-friendly relative folder\n",
    "models_dir = os.path.join(out_dir, \"models\")\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# DEFINE FEATURE SETS\n",
    "feature_sets = {\n",
    "    'plasmid_length':       X_lengths[['Plasmid_Length']],\n",
    "    'domains':              X_domains,\n",
    "    'kmers':                X_kmers,\n",
    "    'domains+plasmid_len':  pd.concat([X_domains, X_lengths[['Plasmid_Length']]], axis=1),\n",
    "    'domains+kmers':        pd.concat([X_domains, X_kmers], axis=1),\n",
    "    'kmers+plasmid_len':    pd.concat([X_kmers, X_lengths[['Plasmid_Length']]], axis=1),\n",
    "    'domains+chrom_len':    pd.concat([X_domains, X_lengths[['Total_Chromosome_Length']]], axis=1),\n",
    "    'kmers+chrom_len':      pd.concat([X_kmers, X_lengths[['Total_Chromosome_Length']]], axis=1),\n",
    "    'domains+kmers+plen':   pd.concat([X_domains, X_kmers, X_lengths[['Plasmid_Length']]], axis=1),\n",
    "    'domains+plen+clen':    pd.concat([X_domains, X_lengths[['Plasmid_Length', 'Total_Chromosome_Length']]], axis=1),\n",
    "    'all_features':         pd.concat([X_domains, X_kmers, X_lengths], axis=1),\n",
    "}\n",
    "\n",
    "# MODEL TRAINING AND EVALUATION \n",
    "results = []\n",
    "\n",
    "for feat_name, X in feature_sets.items():\n",
    "    for rep in range(1, 4):  # 3 replicates\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=rep*42\n",
    "        )\n",
    "\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=rep*42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Save model\n",
    "        model_file = f\"{feat_name.replace('+','_')}_rep{rep}.joblib\"\n",
    "        joblib.dump(model, os.path.join(models_dir, model_file))\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        spear = spearmanr(y_test, y_pred).correlation\n",
    "\n",
    "        results.append({\n",
    "            'feature_set': feat_name,\n",
    "            'replicate': rep,\n",
    "            'r2': r2,\n",
    "            'spearman': spear,\n",
    "            'mae': mae,\n",
    "            'mse': mse\n",
    "        })\n",
    "\n",
    "# SAVE EVALUATION METRICS \n",
    "eval_df = pd.DataFrame(results)\n",
    "eval_file = os.path.join(out_dir, 'evaluation_metrics.csv')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "eval_df.to_csv(eval_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ Models saved in: {models_dir}\")\n",
    "print(f\"✅ Evaluation metrics saved to: {eval_file}\")\n",
    "\n",
    "\n",
    "# Next, we will generate a plot comparing the performance of models trained on different feature sets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Configure matplotlib font and styling\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'Arial',\n",
    "    'font.size': 12,\n",
    "    'axes.linewidth': 1.2,\n",
    "    'xtick.major.size': 6,\n",
    "    'xtick.major.width': 1.2,\n",
    "    'ytick.major.size': 6,\n",
    "    'ytick.major.width': 1.2,\n",
    "    'axes.edgecolor': 'black',\n",
    "    'figure.dpi': 300,\n",
    "    'savefig.dpi': 300\n",
    "})\n",
    "\n",
    "# File paths to save the plots (GitHub-friendly)\n",
    "save_path_pdf  = os.path.join(out_dir, \"Figure_2B.pdf\")\n",
    "\n",
    "# Load the evaluation metrics CSV file\n",
    "eval_df = pd.read_csv(os.path.join(out_dir, \"evaluation_metrics.csv\"))\n",
    "\n",
    "# Clean feature_set names\n",
    "eval_df['feature_set'] = (\n",
    "    eval_df['feature_set']\n",
    "    .str.replace(r'\\+', '&', regex=True)\n",
    "    .str.replace(r'\\s*&\\s*', ' & ', regex=True)\n",
    "    .str.replace(r'\\s+', ' ', regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "def count_features(name: str) -> int:\n",
    "    \"\"\"Count the number of features in a feature set, capped at 4.\"\"\"\n",
    "    parts = [part.strip() for part in name.split('&')]\n",
    "    return min(len(parts), 4)\n",
    "\n",
    "# Compute feature complexity\n",
    "eval_df['complexity'] = eval_df['feature_set'].apply(count_features)\n",
    "\n",
    "# Compute mean and std of R² grouped by feature set\n",
    "stats = (\n",
    "    eval_df\n",
    "    .groupby('feature_set')['r2']\n",
    "    .agg(['mean', 'std'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Assign complexity\n",
    "stats['complexity'] = stats['feature_set'].apply(count_features)\n",
    "stats.loc[stats['feature_set'].str.lower() == 'all features', 'complexity'] = 4\n",
    "\n",
    "# Sort by mean R² for plotting\n",
    "stats = stats.sort_values('mean', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Feature complexity colors\n",
    "feature_colors = {1:'#4E79A7', 2:'#F28E2B', 3:'#E15759', 4:'#76B7B2'}\n",
    "colors = stats['complexity'].map(feature_colors)\n",
    "\n",
    "# Ensure \"All Features\" bar is teal\n",
    "all_features_idx = stats[stats['feature_set'].str.lower() == 'all features'].index\n",
    "for idx in all_features_idx:\n",
    "    colors.iloc[idx] = feature_colors[4]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6), dpi=1200)\n",
    "y_pos = np.arange(len(stats))\n",
    "\n",
    "# Horizontal bars\n",
    "bars = plt.barh(\n",
    "    y_pos,\n",
    "    stats['mean'],\n",
    "    color=colors,\n",
    "    edgecolor='black',\n",
    "    height=0.7\n",
    ")\n",
    "\n",
    "# Error bars\n",
    "plt.errorbar(\n",
    "    stats['mean'],\n",
    "    y_pos,\n",
    "    xerr=stats['std'],\n",
    "    fmt='none',\n",
    "    ecolor='black',\n",
    "    elinewidth=1.5,\n",
    "    capsize=5\n",
    ")\n",
    "\n",
    "# Individual points\n",
    "for i, feature_set in enumerate(stats['feature_set']):\n",
    "    r2_vals = eval_df[eval_df['feature_set'] == feature_set]['r2'].values\n",
    "    plt.scatter(\n",
    "        r2_vals,\n",
    "        np.full_like(r2_vals, y_pos[i]),\n",
    "        color='black',\n",
    "        s=30,\n",
    "        alpha=0.5,\n",
    "        edgecolor='none',\n",
    "        linewidth=0\n",
    "    )\n",
    "\n",
    "# Axis labels\n",
    "plt.yticks(y_pos, stats['feature_set'], fontsize=12)\n",
    "plt.xlabel(r'$R^2$', fontsize=12)\n",
    "plt.xlim(0.5, 0.8)\n",
    "plt.xticks([0.5, 0.6, 0.7, 0.8], fontsize=12)\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.grid(False)\n",
    "\n",
    "# Legend\n",
    "legend_handles = [\n",
    "    Patch(color=color, label=f'{count} feature{\"s\" if count>1 else \"\"}')\n",
    "    for count, color in feature_colors.items()\n",
    "]\n",
    "plt.legend(\n",
    "    handles=legend_handles,\n",
    "    title='Feature complexity',\n",
    "    fontsize=12,\n",
    "    title_fontsize=12,\n",
    "    loc='center left',\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "plt.tight_layout(rect=[0,0,0.85,1])\n",
    "\n",
    "# Save plots\n",
    "plt.savefig(save_path_pdf,  dpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "print(f\"✅ Plot saved to {save_path_tiff}, {save_path_svg}, and {save_path_pdf}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
