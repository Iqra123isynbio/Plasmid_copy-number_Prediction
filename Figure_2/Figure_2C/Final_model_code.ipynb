{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944041a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "#Load your dataset\n",
    "file_path = \"Model_training_data.csv\"\n",
    "# Load the data\n",
    "df = pd.read_csv(file_path)\n",
    "#Select feature columns\n",
    "X_kmers = df.iloc[:, 2:86]  \n",
    "X_domains = df.iloc[:, 86:86 + 1288] \n",
    "X_total_chromosome_length = df[['Total_Chromosome_Length']]  \n",
    "X_plasmid_length = df[['Plasmid_Length']] \n",
    "# Combine all feature columns\n",
    "X = pd.concat([X_kmers, X_domains, X_total_chromosome_length, X_plasmid_length], axis=1)\n",
    "# target variable: Log1p_PIRACopyNumber\n",
    "y = df['Log1p_PIRACopyNumber'] \n",
    "# Split data into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Initialize the Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "#Perform RandomizedSearchCV for hyperparameter tuning\n",
    "param_distributions = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=100, stop=500, num=30)],\n",
    "    'max_features': ['sqrt', 'log2', 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 300, num=30)],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20, 30, 40, 50],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8, 10, 20, 30],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_distributions,\n",
    "                                   n_iter=100, cv=5, verbose=1, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the RandomizedSearchCV to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "#extract the best parameters:\n",
    "best_params_random_search = random_search.best_params_\n",
    "# Get the best parameters\n",
    "print(\"Best Parameters from Randomized Search:\", random_search.best_params_)\n",
    "# Our Best Parameters from Randomized Search for example \n",
    "#Best Parameters from Randomized Search: {'n_estimators': 113, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': 0.4, 'max_depth': 290, 'bootstrap': True}\n",
    "# If you run this code on your own, use the second parameter grid below. It should be tuned based on the values printed above.\n",
    "# These values don't need to be identical, as they depend on the random splits from your specific run, but they should not cause significant deviations in the final output.\n",
    "\n",
    "# Now perform extensive grid search around the best parameters from random search \n",
    "param_grid2 = {\n",
    "    'n_estimators': [best_params_random_search['n_estimators'] - 25, best_params_random_search['n_estimators'], best_params_random_search['n_estimators'] + 25],\n",
    "    'max_features': [best_params_random_search['max_features'], 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'max_depth': [best_params_random_search['max_depth'] - 10, best_params_random_search['max_depth'], best_params_random_search['max_depth'] + 10],\n",
    "    'min_samples_split': [best_params_random_search['min_samples_split'] - 1, best_params_random_search['min_samples_split'], best_params_random_search['min_samples_split'] + 1],\n",
    "    'min_samples_leaf': [1, 2, 3], \n",
    "    'bootstrap': [best_params_random_search['bootstrap']]  \n",
    "}\n",
    "# Initialize GridSearchCV \n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid2, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and score from GridSearchCV\n",
    "best_grid_params = grid_search.best_params_\n",
    "best_grid_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best parameters from GridSearchCV: {best_grid_params}\")\n",
    "print(f\"Best score from GridSearchCV: {best_grid_score}\")\n",
    "# Initialize the final Random Forest model with the best parameters from GridSearchCV\n",
    "rf_model_final = RandomForestRegressor(\n",
    "    n_estimators=best_grid_params['n_estimators'],\n",
    "    max_depth=best_grid_params['max_depth'],\n",
    "    max_features=best_grid_params['max_features'],\n",
    "    min_samples_split=best_grid_params['min_samples_split'],\n",
    "    min_samples_leaf=best_grid_params['min_samples_leaf'],\n",
    "    bootstrap=best_grid_params['bootstrap'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the final model on the entire training data\n",
    "rf_model_final.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "y_pred = rf_model_final.predict(X_test)\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "spearman_corr, _ = spearmanr(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"RÂ²: {r2}\")\n",
    "print(f\"Spearman's Rank Correlation: {spearman_corr}\")\n",
    "\n",
    "# Save actual vs predicted values\n",
    "results_df = pd.DataFrame({\n",
    "    'SampleID': X_test.index if hasattr(X_test, 'index') else range(len(X_test)),\n",
    "    'Actual': y_test.values if hasattr(y_test, 'values') else y_test,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "results_csv_path = \"all_features_actual_vs_predicted_final.csv\"\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "\n",
    "# Save evaluation metrics summary\n",
    "metrics_df = pd.DataFrame([{\n",
    "    'Feature_Set': 'All Features',\n",
    "    'R2': r2,\n",
    "    'MAE': mae,\n",
    "    'MSE': mse,\n",
    "    'Spearman': spearman_corr\n",
    "}])\n",
    "\n",
    "metrics_csv_path = \"all_features_evaluation_metrics_final.csv\"\n",
    "metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "\n",
    "print(f\"Saved actual vs predicted values to {results_csv_path}\")\n",
    "print(f\"Saved evaluation metrics summary to {metrics_csv_path}\")\n",
    "\n",
    "# Save the model\n",
    "model_path = \"/rf_model_final.pkl\"\n",
    "joblib.dump(rf_model_final, model_path)\n",
    "print(f\"Model saved at: {model_path}\")\n",
    "\n",
    "# Back-transform the targets and predictions (inverse of log1p)\n",
    "y_test_orig = np.expm1(y_test)  # Back-transform actual values\n",
    "y_pred_orig = np.expm1(y_pred)\n",
    "\n",
    "# Back-transform actual values and save to the actual vs predicted final file\n",
    "\n",
    "df=pd.read_csv('all_features_actual_vs_predicted_final.csv')\n",
    "x0=df.iloc[:,3]\n",
    "y0=df.iloc[:,4]\n",
    "# Assume x0, y0 already defined\n",
    "\n",
    "XX1 = np.log10(x0)\n",
    "YY1 = np.log10(y0)\n",
    "# Filter out NaN and inf values\n",
    "valid_mask = ~np.isnan(XX1) & ~np.isinf(XX1) & ~np.isnan(YY1) & ~np.isinf(YY1)\n",
    "XX1 = XX1[valid_mask]\n",
    "YY1 = YY1[valid_mask]\n",
    "\n",
    "# Calculate the density\n",
    "xy = np.vstack([XX1, YY1])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "XX1, YY1, z = XX1.iloc[idx], YY1.iloc[idx], z[idx]\n",
    "\n",
    "plt.figure(figsize=(3, 2))\n",
    "# Use density values for coloring\n",
    "sc = plt.scatter(XX1, YY1, c=z, marker='o', s=5, edgecolor=None, cmap='Reds', vmin=0, vmax=0.8)\n",
    "\n",
    "# Add colorbar for point density\n",
    "cb = plt.colorbar(sc)\n",
    "cb.set_label('Point Density', fontsize=8)\n",
    "\n",
    "# Perform linear regression using statsmodels\n",
    "X = sm.add_constant(XX1)\n",
    "model = sm.OLS(YY1, X).fit()\n",
    "\n",
    "# Generate points for the regression line\n",
    "x_fit = np.linspace(XX1.min(), XX1.max(), 100)\n",
    "X_fit = sm.add_constant(x_fit)\n",
    "y_fit = model.predict(X_fit)\n",
    "\n",
    "# Calculate the confidence interval\n",
    "prediction = model.get_prediction(X_fit)\n",
    "ci = prediction.conf_int()\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(x_fit, y_fit, color='red', linewidth=1)\n",
    "\n",
    "# Plot the confidence interval\n",
    "plt.fill_between(x_fit, ci[:, 0], ci[:, 1], color='red', alpha=0.2)\n",
    "\n",
    "# Calculate and print Spearman correlation\n",
    "corr, p_value = spearmanr(XX1, YY1)\n",
    "print(f\"Spearman's rho: {corr:.3f}, p-value: {p_value:.3g}\")\n",
    "\n",
    "plt.xlabel('Actual PCN (log10)')\n",
    "plt.ylabel('Predicted PCN (log10)')\n",
    "plt.savefig('fig1d.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
